#!/bin/env bash

# Benchmark info
echo "TIMING - Starting main script at: $(date)"

# Set working directory 
cd "${HEAVYAIBASE}"

<%- unless context.modules.blank? -%>
# Purge the module environment to avoid conflicts
module purge

# Load the require modules
module load <%= context.modules %>

# List loaded modules
module list
<%- end -%>

set -x
# Benchmark info
echo "TIMING - Starting omnisci at: $(date)"
#export container_image=/n/singularity_images/OOD/omnisci/v5.5.5/omnisci-ee-cuda_v5.5.5.sif
export container_image=<%= context.heavyai_version %>

export SING_GPU=""

<%- if !context.custom_num_gpus.to_i.zero? -%>
export SING_GPU="--nv "
<%- end -%>

## bind some extra stuff to be able to talk to slurm from within the container
export SING_BINDS=" -B /etc/nsswitch.conf -B /etc/sssd/ -B /var/lib/sss -B /etc/slurm -B /slurm -B /var/run/munge  -B `which sbatch ` -B `which srun ` -B `which sacct ` -B `which scontrol `   -B /usr/lib64/slurm/ "

## bind heavyAI HEAVYAI_BASE
export SING_BINDS="$SING_BINDS -B ${HEAVYAIBASE}/var/lib/heavyai:/var/lib/heavyai "

SINGULARITYENV_MAPD_WEB_PORT=${MAPD_WEB_PORT} SINGULARITYENV_MAPD_TCP_PORT=${MAPD_TCP_PORT} SINGULARITYENV_MAPD_HTTP_PORT=${MAPD_HTTP_PORT} SINGULARITYENV_MAPD_CALCITE_PORT=${MAPD_CALCITE_PORT} singularity run $SING_GPU $SING_BINDS --pwd /opt/heavyai $container_image

